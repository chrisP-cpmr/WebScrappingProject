{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moral-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install requests beautifulsoup4 lxml\n",
    "# ! pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "empirical-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021-05, Christoph Meier, https://github.com/chrisP-cpmr\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-muscle",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "otherwise-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allsundays(year):\n",
    "    d = date(year, 1, 1)                    # January 1st\n",
    "    d += timedelta(days = 6 - d.weekday())  # First Sunday\n",
    "    while d.year == year:\n",
    "        yield d.strftime('%d-%m-%Y')\n",
    "        d += timedelta(days = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-cloud",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alert-latter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the first Sunday of the current year to complete base url\n",
    "today = datetime.today()\n",
    "year = today.year\n",
    "actualYearSun = list(allsundays(year))\n",
    "firstSunday = actualYearSun[0]\n",
    "\n",
    "url = \"https://hitparade.ch/charts/singles/\" + firstSunday\n",
    "\n",
    "# create user agent for chromium on linux\n",
    "user_agent = (\n",
    "    'Mozilla/5.0 (X11; Linux x86_64)'\n",
    "    ' AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "    ' Chrome/90.0.4430.93 Safari/537.36'\n",
    ")\n",
    "\n",
    "# create header\n",
    "headers = {'User-Agent': user_agent}\n",
    "\n",
    "# grab web page content\n",
    "# with request.get() we will get the complete html content of the webpage we are calling\n",
    "html = requests.get(url, headers=headers)\n",
    "\n",
    "# convert to a beautiful soup object\n",
    "page_soup = bs(html.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raising-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_item = page_soup.find(\"div\", class_=\"content chartitem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legislative-amber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank = chart_item.find(\"div\", class_=\"chart_pos\").getText().strip()\n",
    "Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-beads",
   "metadata": {},
   "source": [
    "# Complete Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-tissue",
   "metadata": {},
   "source": [
    "### Get info for URL\n",
    "In order to return the complete charts for every week, we need the sundays for every year since 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-geometry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get info about all potential weeks and years to scrape\n",
    "\n",
    "# weeks = []\n",
    "# years = []\n",
    "\n",
    "# selector = page_soup.find(\"div\", class_=\"chart_selector_table_cell\")\n",
    "# yearSelector = selector.find_all(\"select\")[1]\n",
    "# for year in yearSelector.find_all(\"option\"):\n",
    "#     years.append(year.getText())\n",
    "\n",
    "# selector = page_soup.find(\"div\", class_=\"chart_selector_table_cell\")\n",
    "# weekSelector = selector.find(\"select\")\n",
    "# for week in weekSelector.find_all(\"option\"):\n",
    "#     weeks.append(week.getText().replace(\".\", \"-\"))\n",
    "    \n",
    "    \n",
    "# print(years)\n",
    "# print(\"Weeks: \", weeks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get every Sunday since 1990\n",
    "       \n",
    "weeks = []\n",
    "years = list(range(1990, 2021))\n",
    "\n",
    "for year in years:\n",
    "    for d in allsundays(year):\n",
    "        weeks.append(d)\n",
    "        \n",
    "selector = page_soup.find(\"div\", class_=\"chart_selector_table_cell\")\n",
    "weekSelector = selector.find(\"select\")\n",
    "for week in weekSelector.find_all(\"option\"):\n",
    "    weeks.append(week.getText().replace(\".\", \"-\"))\n",
    "    \n",
    "print(len(weeks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "outstanding-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time for delay and \n",
    "delay = 10\n",
    "\n",
    "# create file\n",
    "filename = \"charts.csv\"\n",
    "f = open(filename, \"w\")\n",
    "\n",
    "# create and write headers\n",
    "fileHeaders = \"VW, ArtistAndTitle, WeeksAndPeak, Week\\n\"\n",
    "f.write(fileHeaders)\n",
    "\n",
    "# VW_col = []\n",
    "# ArtistAndTitle_col = []\n",
    "# WeeksAndPeak_col = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for week in weeks:\n",
    "    url = \"https://hitparade.ch/charts/singles/\" + week\n",
    "    html = requests.get(url, headers=headers)\n",
    "    page_soup = bs(html.content, \"lxml\")\n",
    "    for chartItem in page_soup.find_all(\"div\", class_=\"content chartitem\"):\n",
    "        VW = chartItem.find(\"div\", class_=\"chart_lw notmobile\").getText().strip()\n",
    "        ArtistAndTitle = chartItem.find(\"div\", class_=\"chart_title\").getText().strip()\n",
    "        WeeksAndPeak = chartItem.find(\"span\", class_=\"wp\").getText().strip()\n",
    "        rank\n",
    "        # VW_col.append(VW)\n",
    "        # ArtistAndTitle_col.append(ArtistAndTitle)\n",
    "        # WeeksAndPeak_col.append(WeeksAndPeak)\n",
    "        # we have to replace all comas in artist names or titles to ensure no wrong spacing in the .csv\n",
    "        f.write(VW + \",\" + ArtistAndTitle.replace(\",\", \"|\") + \",\" + WeeksAndPeak + \",\" + week + \"\\n\")\n",
    "    time.sleep(delay)\n",
    "    count += 1\n",
    "    if count == len(weeks):\n",
    "        break\n",
    "    \n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-glossary",
   "metadata": {},
   "source": [
    "## Get \"Vorwoche\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deluxe-brown",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VW 1\n",
      "VW 2\n",
      "VW 3\n",
      "VW 6\n",
      "VW 7\n",
      "VW 8\n",
      "VW 4\n",
      "VW 10\n",
      "neu\n",
      "VW 9\n",
      "VW 11\n",
      "VW 12\n",
      "VW 13\n",
      "VW 17\n",
      "VW 5\n",
      "VW 16\n",
      "VW 15\n",
      "VW 14\n",
      "VW 38\n",
      "VW 19\n",
      "VW 34\n",
      "VW 21\n",
      "VW 18\n",
      "VW 25\n",
      "VW 22\n",
      "VW 23\n",
      "VW 26\n",
      "VW 27\n",
      "VW 20\n",
      "VW 24\n",
      "VW 28\n",
      "VW 29\n",
      "VW 33\n",
      "VW 32\n",
      "VW 30\n",
      "VW 31\n",
      "VW 51\n",
      "neu\n",
      "VW 45\n",
      "neu\n",
      "VW 44\n",
      "VW 37\n",
      "VW 42\n",
      "VW 39\n",
      "VW 36\n",
      "VW 57\n",
      "VW 43\n",
      "VW 40\n",
      "VW 35\n",
      "neu\n",
      "VW 55\n",
      "VW 52\n",
      "VW 54\n",
      "VW 73\n",
      "VW 46\n",
      "VW 59\n",
      "VW 48\n",
      "VW 62\n",
      "VW 61\n",
      "VW 64\n",
      "VW 63\n",
      "neu\n",
      "VW 41\n",
      "VW 60\n",
      "VW 70\n",
      "VW 47\n",
      "VW 58\n",
      "VW 67\n",
      "VW 65\n",
      "VW 74\n",
      "VW 72\n",
      "VW 71\n",
      "VW 66\n",
      "VW 79\n",
      "VW 76\n",
      "neu\n",
      "VW 87\n",
      "VW 94\n",
      "neu\n",
      "VW 91\n",
      "VW 78\n",
      "VW 81\n",
      "VW 69\n",
      "VW 84\n",
      "neu\n",
      "VW 98\n",
      "VW 95\n",
      "VW 83\n",
      "VW 85\n",
      "VW 97\n",
      "VW 99\n",
      "neu\n",
      "VW 86\n",
      "VW 88\n",
      "re\n",
      "re\n",
      "re\n",
      "neu\n",
      "re\n",
      "re\n"
     ]
    }
   ],
   "source": [
    "for divChartItem in soup.find_all(\"div\", class_=\"content chartitem\"):\n",
    "    print(divChartItem.find(\"div\", class_=\"chart_lw notmobile\").getText().strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-young",
   "metadata": {},
   "source": [
    "## Get artist + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "digital-alignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nathan EvansWellerman\n",
      "Lil Nas XMontero (Call Me By Your Name)\n",
      "Justin Bieber feat. Daniel Caesar & GiveonPeaches\n",
      "Riton x Nightcrawlers feat. Mufasa & HypemanFriday (Dopamine Re-Edit)\n",
      "P!nk + Willow Sage HartCover Me In Sunshine\n",
      "Masked WolfAstronaut In The Ocean\n",
      "Luciano [DE]Kids From The Block\n",
      "atb x Topic x A7SYour Love (9PM)\n",
      "Capital Bra & NGEEUnter Verdacht\n",
      "TiÃ«stoThe Business\n",
      "The WeekndSave Your Tears\n",
      "Zoe WeesGirls Like Us\n",
      "Master KG feat. Burna Boy & Nomcebo ZikodeJerusalema (Remix)\n",
      "Ofenbach feat. LagiqueWasted Love\n",
      "Santos x Sido x SamraLeere HÃ¤nde\n",
      "HVMEGoosebumps\n",
      "Duncan LaurenceArcade\n",
      "Polo GRapstar\n",
      "Dua LipaLevitating\n",
      "The Kid LaroiWithout You\n",
      "Aurora [NO]Runaway\n",
      "The WeekndBlinding Lights\n",
      "Miksu / Macloud, Nimo & JamuleFrag mich nicht\n",
      "LeonyFaded Love\n",
      "Ed SheeranAfterglow\n",
      "Silk Sonic - Bruno Mars & Anderson .PaakLeave The Door Open\n",
      "Joel Corry feat. MNEKHead & Heart\n",
      "Imagine DragonsFollow You\n",
      "Olivia RodrigoDrivers License\n",
      "Jason Derulo x NukaLove Not War (The Tampa Beat)\n",
      "Meduza feat. Dermot KennedyParadise\n",
      "24kGoldn feat. Iann DiorMood\n",
      "Ava MaxMy Head & My Heart\n",
      "Doja Cat feat. SZAKiss Me More\n",
      "Robin Schulz feat. KiddoAll We Got\n",
      "Ofenbach & Quarterhead feat. Norma Jean MartineHead Shoulders Knees & Toes\n",
      "GazoHaine&Sex\n",
      "Young Stoner Life / Young Thug / Gunna feat. DrakeSolid\n",
      "J Balvin & KhalidOtra noche sin ti\n",
      "Ufo361 feat. Data LuvAngekommen\n",
      "Olivia RodrigoDeja Vu\n",
      "Vize x Tokio HotelWhite Lies\n",
      "Sia x David GuettaFloating Through Space\n",
      "Bad Bunny x Jhay CortezDÃ¡kiti\n",
      "GiveonHeartbreak Anniversary\n",
      "Tom OdellAnother Love\n",
      "Tones And IDance Monkey\n",
      "Justin BieberHold On\n",
      "Luciano [DE]Peppermint\n",
      "AK AusserkontrolleUnter dem Radar\n",
      "Harry StylesWatermelon Sugar\n",
      "Lewis CapaldiSomeone You Loved\n",
      "Purple Disco Machine & Sophie And The GiantsHypnotized\n",
      "Wincent WeissWer wenn nicht wir\n",
      "Nimo x LucianoBad Eyez\n",
      "Joel Corry, Raye & David GuettaBed\n",
      "CJWhoopty\n",
      "Russ Millions x Tion WayneBody\n",
      "ZianShow You\n",
      "Maroon 5 feat. Megan Thee StallionBeautiful Mistakes\n",
      "Tate McRaeYou Broke Me First\n",
      "Kygo feat. James GillespieGone Are The Days\n",
      "JamuleOverdose\n",
      "Internet Money & Gunna feat. Don Toliver & NavLemonade\n",
      "David Guetta feat. Kid CudiMemories\n",
      "Kali UchisTelepatÃ­a\n",
      "Bausa feat. Apache 207Madonna\n",
      "SAINt JHNRoses (Imanbek Remix)\n",
      "Jawsh 685 & Jason DeruloSavage Love (Laxed - Siren Beat)\n",
      "Topic feat. A7SBreaking Me\n",
      "Glass AnimalsHeat Waves\n",
      "RegardRide It\n",
      "Black Eyed Peas x ShakiraGirl Like Me\n",
      "Lady Gaga & Bradley CooperShallow\n",
      "Lo & LeducTribut\n",
      "Tom GrennanLittle Bit Of Love\n",
      "Tones And IFly Away\n",
      "Dua LipaWe're Good\n",
      "DJ Jeezy feat. Summer Cem, JAY1 & NimoOK\n",
      "DaBaby feat. Roddy RicchRockstar\n",
      "Apache 207Roller\n",
      "Cardi BUp\n",
      "Lil Tjay feat. 6lackCalling My Phone\n",
      "Kizz Daniel feat. PhilkeyzNesesari\n",
      "Wisin, Jhay Cortez, Los LegendariosFiel\n",
      "TwocolorsLovefool\n",
      "Ava MaxKings & Queens\n",
      "Zoe WeesControl\n",
      "TaycLe temps\n",
      "Booba feat. JSXMona Lisa\n",
      "BozaHecha pa' mÃ­\n",
      "Young Stoner Life / Young Thug / Gunna feat. Travis ScottDiamonds Dancing\n",
      "Moha KVroum vroum\n",
      "Lil Nas XHoliday\n",
      "Macklemore & Ryan Lewis feat. Ray DaltonCan't Hold Us\n",
      "Jason DeruloTake You Dancing\n",
      "Dua Lipa feat. AngÃ¨leFever\n",
      "Bruno MarsTalking To The Moon\n",
      "Justin Wellington and Small JamIko Iko\n",
      "Selena Gomez & Rauw AlejandroBaila conmigo\n"
     ]
    }
   ],
   "source": [
    "for divChartItem in soup.find_all(\"div\", class_=\"content chartitem\"):\n",
    "    print(divChartItem.find(\"div\", class_=\"chart_title\").getText().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-difference",
   "metadata": {},
   "source": [
    "## Get number of week in charts + peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "earned-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W 13 | P 1\n",
      "W 4 | P 2\n",
      "W 5 | P 2\n",
      "W 10 | P 3\n",
      "W 10 | P 5\n",
      "W 13 | P 4\n",
      "W 2 | P 4\n",
      "W 14 | P 6\n",
      "W 1 | P 9\n",
      "W 24 | P 4\n",
      "W 15 | P 3\n",
      "W 14 | P 3\n",
      "W 43 | P 1\n",
      "W 7 | P 14\n",
      "W 2 | P 5\n",
      "W 27 | P 12\n",
      "W 22 | P 6\n",
      "W 2 | P 14\n",
      "W 29 | P 19\n",
      "W 20 | P 10\n",
      "W 2 | P 21\n",
      "W 73 | P 1\n",
      "W 4 | P 11\n",
      "W 7 | P 24\n",
      "W 18 | P 2\n",
      "W 7 | P 23\n",
      "W 40 | P 4\n",
      "W 6 | P 25\n",
      "W 15 | P 2\n",
      "W 22 | P 5\n",
      "W 25 | P 14\n",
      "W 35 | P 1\n",
      "W 15 | P 19\n",
      "W 2 | P 32\n",
      "W 27 | P 4\n",
      "W 37 | P 6\n",
      "W 3 | P 37\n",
      "W 1 | P 38\n",
      "W 2 | P 39\n",
      "W 1 | P 40\n",
      "W 3 | P 41\n",
      "W 10 | P 28\n",
      "W 11 | P 42\n",
      "W 25 | P 12\n",
      "W 7 | P 34\n",
      "W 94 | P 23\n",
      "W 89 | P 1\n",
      "W 7 | P 16\n",
      "W 7 | P 4\n",
      "W 1 | P 50\n",
      "W 52 | P 3\n",
      "W 118 | P 3\n",
      "W 32 | P 18\n",
      "W 7 | P 54\n",
      "W 9 | P 13\n",
      "W 5 | P 56\n",
      "W 26 | P 10\n",
      "W 3 | P 58\n",
      "W 15 | P 26\n",
      "W 4 | P 60\n",
      "W 36 | P 13\n",
      "W 1 | P 62\n",
      "W 3 | P 26\n",
      "W 36 | P 3\n",
      "W 57 | P 7\n",
      "W 8 | P 36\n",
      "W 9 | P 8\n",
      "W 71 | P 2\n",
      "W 45 | P 1\n",
      "W 67 | P 4\n",
      "W 10 | P 69\n",
      "W 82 | P 2\n",
      "W 16 | P 28\n",
      "W 133 | P 1\n",
      "W 22 | P 4\n",
      "W 1 | P 76\n",
      "W 17 | P 30\n",
      "W 10 | P 38\n",
      "W 1 | P 79\n",
      "W 53 | P 1\n",
      "W 70 | P 4\n",
      "W 11 | P 47\n",
      "W 10 | P 10\n",
      "W 8 | P 45\n",
      "W 1 | P 85\n",
      "W 44 | P 19\n",
      "W 58 | P 5\n",
      "W 49 | P 11\n",
      "W 8 | P 10\n",
      "W 7 | P 7\n",
      "W 15 | P 56\n",
      "W 1 | P 92\n",
      "W 4 | P 70\n",
      "W 19 | P 26\n",
      "W 54 | P 4\n",
      "W 38 | P 11\n",
      "W 24 | P 9\n",
      "W 1 | P 98\n",
      "W 2 | P 99\n",
      "W 11 | P 28\n"
     ]
    }
   ],
   "source": [
    "for divChartItem in soup.find_all(\"div\", class_=\"content chartitem\"):\n",
    "    print(divChartItem.find(\"span\", class_=\"wp\").getText().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-local",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
